# Authors
- **Amir Ammar**  
  ID: 205744873

- **Tamir Smith**  
  ID: 215173071

## About the Project
This project focuses on hand gesture recognition and triggers corresponding applications or websites when a specific gesture is recognized. For additional information, please review the README.md file.


## File Description

### ContinuousGesturePredictor-Amir-Tamir.py
This script opens a camera video feed and captures human hand gestures. The program includes a `limit` variable to ensure the detected hand gesture is accurate before triggering the corresponding application or website.

### modeltrainer2.ipynb
This Jupyter Notebook is used to train the hand gesture recognition model. It is similar to `modeltrainer.ipynb`, but includes an additional gesture (Thumb-Up) for training.


# Links 

### https://github.com/SparshaSaha/Hand-Gesture-Recognition-Using-Background-Elllimination-and-Convolution-Neural-Network/

includes the DataBase for 3 hand gesture 


### https://www.kaggle.com/datasets/roobansappani/hand-gesture-recognition

this link is for additional gesture (Thumb-Up) that we added to train our model 



## How to run the RealTime prediction

Run the [ContinuousGesturePredictor-Amir-Tamir.py](https://github.com/SparshaSaha/Hand-Gesture-Recognition-Using-Background-Elllimination-and-Convolution-Neural-Network/blob/master/ContinuousGesturePredictor.py) file and you will see a window named **Video Feed** appear on screen. Wait for a while until a window named **Thresholded** appears.

The next step involves pressing **"s"** on your keyboard in order to start the real-time prediction.

Bring your hand in the **Green Box** drawn inside **Video Feed** window in order to see the predictions.
Look in demo for some visual clarity.



## Customize  

To customize the application's functionality, modify the code between lines 153 and 179 to suit your needs.


